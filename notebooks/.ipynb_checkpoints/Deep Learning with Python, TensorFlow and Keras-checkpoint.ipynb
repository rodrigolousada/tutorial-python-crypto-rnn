{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python, TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rodrigo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2612 - acc: 0.9230\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1068 - acc: 0.9671\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0727 - acc: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a702d57f28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist #28x28 images of hand-written digits 0-9\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.0889 - acc: 0.9725\n",
      "0.08890597861856223 0.9725\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a704ae2198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.1032865e-11 7.6528659e-09 5.5962079e-07 ... 9.9999726e-01\n",
      "  3.0483878e-09 7.6165527e-08]\n",
      " [9.0201235e-11 1.8717711e-04 9.9981195e-01 ... 1.5351453e-09\n",
      "  6.8665806e-09 2.6567498e-14]\n",
      " [2.5295105e-07 9.9933201e-01 6.6281369e-05 ... 5.2417506e-04\n",
      "  4.6104291e-05 3.8323668e-07]\n",
      " ...\n",
      " [7.0993131e-09 1.5353877e-06 5.4229236e-08 ... 2.3781662e-04\n",
      "  1.2605664e-06 1.2558460e-04]\n",
      " [2.5699640e-07 6.0864181e-06 3.5352933e-08 ... 3.4745125e-07\n",
      "  8.9241083e-05 6.5642574e-08]\n",
      " [5.3476504e-07 8.0585833e-06 2.9081230e-06 ... 3.6166520e-07\n",
      "  1.3176783e-06 1.2062418e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a704e298d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
